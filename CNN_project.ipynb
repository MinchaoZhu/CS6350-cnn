{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "class ConvolutionLayer:\n",
    "  # A Convolution layer\n",
    "\n",
    "    # generate random matrix\n",
    "    def generateRandomMatrix(self): \n",
    "        rand = self.channel * self.width * self.height;\n",
    "        matrix = np.zeros((self.channel, self.width, self.height))\n",
    "        for i in range (self.channel):\n",
    "            for j in range (self.width):\n",
    "                for k in range (self.height):\n",
    "                    matrix[i][j][k] = np.random.normal(loc = 0, scale = np.sqrt(1. / rand))\n",
    "        return matrix\n",
    "\n",
    "    # create filter matrix\n",
    "    def createFilterMatrix(self):\n",
    "        for i in range(self.num_filters):\n",
    "            # initialize filter matrix with random\n",
    "            self.weights[i] = self.generateRandomMatrix()\n",
    "        return \n",
    "\n",
    "    # initialization function to create convolutional layer instance\n",
    "    def __init__(self, inputs_channel, num_filters, width, height, padding, stride, learning_rate):\n",
    "\n",
    "        # number of convolutional filter as defined, it is required to be at least 1\n",
    "        if num_filters <=0: \n",
    "             print(\"invalid filter number is provided.\")\n",
    "             return\n",
    "        else:\n",
    "            self.num_filters = num_filters\n",
    "            # bias matrix is set to all zero initially\n",
    "            self.bias = np.zeros((self.num_filters,1))\n",
    "        # number of image channels. In the project, all image channel is decided to be 1 for gray image\n",
    "        if inputs_channel <=0: \n",
    "             print(\"invalid channel number is provided.\")\n",
    "             return\n",
    "        else:\n",
    "            self.channel = inputs_channel\n",
    "        # width of input images\n",
    "        if width <=0: \n",
    "             print(\"invalid width of matrix is provided.\")\n",
    "             return\n",
    "        else:\n",
    "            self.width = width\n",
    "        # height of input images\n",
    "        if height <=0: \n",
    "             print(\"invalid height of matrix is provided.\")\n",
    "             return\n",
    "        else:\n",
    "            self.height = height\n",
    "            # create random convolutional matrix\n",
    "            self.weights = np.zeros((self.num_filters, self.channel, self.width, self.height))\n",
    "        # step size of convolutional matrix's sliding step\n",
    "        if stride <=0: \n",
    "             print(\"Value of stride needs to be greater than 0 to be meaningful.\")\n",
    "             return\n",
    "        else:\n",
    "            self.stride = stride\n",
    "        # padding for result\n",
    "        if padding < 0: \n",
    "             print(\"padding can't be negative value.\")\n",
    "             return\n",
    "        else:\n",
    "            self.padding = padding\n",
    "        # learning rate for gradient descent study\n",
    "        if learning_rate  < 0: \n",
    "            print(\"Please provide a positive learning rate\")\n",
    "        else:\n",
    "            self.lr = learning_rate\n",
    "\n",
    "    \n",
    "    def paddingInclusion(self, inputs):\n",
    "        # get input image's shape and calculate result image shape including padding size\n",
    "        w = inputs.shape[0]\n",
    "        h = inputs.shape[1]\n",
    "        # new shape of matrix after considering padding\n",
    "        new_w = 2 * self.padding + w\n",
    "        new_h = 2 * self.padding + h\n",
    "        out = np.zeros((new_w, new_h))\n",
    "        # fill those zero spots by input values and rest will be left as it is\n",
    "        for i in range(new_w):\n",
    "            for j in range(new_h):\n",
    "                if i >= self.padding and i < self.padding + w and j >= self.padding and j < self.padding + h:\n",
    "                    out[i][j] = inputs[i-self.padding][j-self.padding]\n",
    "        return out\n",
    "\n",
    "    def sumResultOfMatrix(self, changedMatrix):\n",
    "        f = changedMatrix.shape[0]\n",
    "        w = changedMatrix.shape[1]\n",
    "        h = changedMatrix.shape[2]\n",
    "        result = 0\n",
    "        for i in range(f):\n",
    "            for j in range(w):\n",
    "                for k in range(h):\n",
    "                    result += changedMatrix[i][j][k]\n",
    "        return result\n",
    "\n",
    "\n",
    "    def calculateForwardMatrix(self, new_width, new_height):\n",
    "        # corner check\n",
    "        if new_width > 0 and new_height > 0:\n",
    "            forward_matrix = np.zeros((self.num_filters, new_width, new_height))\n",
    "            for f in range(self.num_filters):\n",
    "                for w in range(new_width):\n",
    "                    for h in range(new_height):\n",
    "                        changedMatrix = self.inputs[:,w:w+self.width,h:h+self.height]*self.weights[f,:,:,:]\n",
    "                        # sum up result to form forward matrix\n",
    "                        forward_matrix[f,w,h]= self.sumResultOfMatrix(changedMatrix)+self.bias[f]\n",
    "            return forward_matrix\n",
    "        else:\n",
    "            print(\"either width or height is invalid\")\n",
    "            return\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # get input shape, height, width and channel\n",
    "        channel = inputs.shape[0]\n",
    "        padding = 2 * self.padding\n",
    "        stride = self.stride\n",
    "        process_width = padding + inputs.shape[1]\n",
    "        process_height = padding + inputs.shape[2]\n",
    "        self.inputs = np.zeros((channel, process_width, process_height))\n",
    "        for ch in range(channel):\n",
    "            # process padding\n",
    "            self.inputs[ch] = self.paddingInclusion(inputs[ch])\n",
    "        new_width = (process_width - self.width)//stride + 1\n",
    "        new_height = (process_height - self.height)//stride + 1\n",
    "        return self.calculateForwardMatrix(new_width, new_height)\n",
    "\n",
    "    def backward(self, dy):\n",
    "        inputs = self.inputs\n",
    "        weights = self.weights\n",
    "        bias = self.bias\n",
    "        src = np.zeros((inputs.shape[0], inputs.shape[1], inputs.shape[2]))\n",
    "        wei = np.zeros((weights.shape[0], weights.shape[1], weights.shape[2]))\n",
    "        bi = np.zeros((bias.shape[0], bias.shape[1], bias.shape[2]))\n",
    "\n",
    "        fil, width, height = dy.shape\n",
    "        if fil > 0 and width > 0 and height > 0:\n",
    "            for f in range(fil):\n",
    "                for w in range(width):\n",
    "                    for h in range(height):\n",
    "                        wei[f]+=dy[f,w,h]*self.inputs[:,w:w+self.width,h:h+self.height]\n",
    "                        src[:,w:w+self.width,h:h+self.height]+=dy[f,w,h]*self.weights[f,:,:,:]\n",
    "        else:\n",
    "            return\n",
    "\n",
    "        for f in range(fil):\n",
    "            sum = 0;\n",
    "            target_matrix = dy[f]\n",
    "            for i in range (target_matrix.shape[0]):\n",
    "                for j in range (target_matrix.shape[1]):\n",
    "                    sum += target_matrix[i][j]\n",
    "            bi[f] = sum\n",
    "\n",
    "        self.weights -= self.lr * wei\n",
    "        self.bias -= self.lr * bi\n",
    "        return src\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLu:\n",
    "    def forward(self, inputs):\n",
    "        self.inputs = inputs\n",
    "        relu = inputs.copy()\n",
    "        # change the value that is less than 0 to 0\n",
    "        relu[relu < 0] = 0\n",
    "        return relu\n",
    "\n",
    "    def backward(self, dy):\n",
    "        inputs = dy.copy()\n",
    "        inputs[self.inputs < 0] = 0\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPoolingLayer:\n",
    "    def __init__(self, width, height, stride):\n",
    "        if width > 0:\n",
    "            self.width = width\n",
    "        else:\n",
    "            sys.exit(\"width cannot be negative\") \n",
    "        if height > 0:\n",
    "            self.height = height\n",
    "        else:\n",
    "            sys.exit(\"height cannot be negative\") \n",
    "        if stride > 0:\n",
    "            self.stride = stride\n",
    "        else:\n",
    "            sys.exit(\"stride cannot be negative\") \n",
    "\n",
    "    def new_demension(self, current, old, stride):\n",
    "        if current > 0 and old > 0 and stride > 0:\n",
    "            return (current - old) // stride + 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def array_slice(self, i1, i2, j1, j2, k1, k2):\n",
    "        return self.inputs[i1, j1:j2, k1:k2]\n",
    "\n",
    "    def arr_max(self, arr):\n",
    "        result = np.max(arr[0])\n",
    "        for v in arr:\n",
    "            result = max(np.max(v), result)\n",
    "        return result\n",
    "\n",
    "    def forward_out(self, c_len, new_width, new_height):\n",
    "        out = 0\n",
    "        if c_len >= 0 and new_width >= 0 and new_height >= 0:\n",
    "            out = np.zeros((c_len, new_width, new_height))\n",
    "        else:\n",
    "            sys.exit(\"Inputs should not be negative\") \n",
    "        c = 0\n",
    "        w = 0\n",
    "        h = 0\n",
    "        flag_c = True\n",
    "        flag_w = True\n",
    "        flag_h = True\n",
    "        while flag_c:\n",
    "            while flag_w:\n",
    "                while flag_h:\n",
    "                    new_c = c\n",
    "                    new_c_2 = c + 1\n",
    "                    new_w_1 = self.stride * w\n",
    "                    new_w_2 = new_w_1 + self.width\n",
    "                    new_h_1 = h * self.stride\n",
    "                    new_h_2 = new_h_1 + self.height\n",
    "                    result = self.array_slice(new_c, new_c_2, new_w_1, new_w_2, new_h_1, new_h_2)\n",
    "                    out[c, w, h] = self.arr_max(result)\n",
    "                    h += 1\n",
    "                    flag_h = h < new_height\n",
    "                w += 1\n",
    "                flag_w = w < new_width\n",
    "            c += 1\n",
    "            flag_c = c < c_len\n",
    "        return out\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        if inputs is not None:\n",
    "            self.inputs = inputs\n",
    "        else:\n",
    "            sys.exit(\"Inputs should not be None\") \n",
    "\n",
    "        c_len, w_len, h_len = inputs.shape\n",
    "        new_width = self.new_demension(w_len, self.width, self.stride)\n",
    "        new_height = self.new_demension(h_len, self.height, self.stride)\n",
    "        result = self.forward_out(c_len,new_width, new_height)\n",
    "        if result is not None:\n",
    "            return result\n",
    "        else:\n",
    "            sys.exit(\"error: output is none\") \n",
    "\n",
    "    def index_to_tuple(index, m, n):\n",
    "        x = int(index / n)\n",
    "        y = index - n * x\n",
    "        return x, y\n",
    "\n",
    "    def backward_out(self, c_len, w_len, h_len, delta_y):\n",
    "        dx = np.zeros(self.inputs.shape)\n",
    "        c = 0\n",
    "        w = 0\n",
    "        h = 0\n",
    "        flag_c = True\n",
    "        flag_w = True\n",
    "        flag_h = True\n",
    "        while flag_c:\n",
    "            while flag_w:\n",
    "                while flag_h:\n",
    "                    new_c = c\n",
    "                    new_c_2 = c + 1\n",
    "                    new_w_1 = w\n",
    "                    new_w_2 = new_w_1 + self.width\n",
    "                    new_h_1 = h\n",
    "                    new_h_2 = new_h_1 + self.height\n",
    "                    result = self.array_slice(new_c, new_c_2, new_w_1, new_w_2, new_h_1, new_h_2)\n",
    "                    x, y = self.index_to_tuple(np.argmax(result), new_w_1, new_h_1)\n",
    "                    new_w_1 += x\n",
    "                    new_h_1 += y\n",
    "                    dx[new_c, new_w_1, new_h_1] = delta_y[c, w // self.width, h // self.height]\n",
    "                    h += self.height\n",
    "                    flag_h = h < h_len\n",
    "                w += self.width\n",
    "                flag_w = w < w_len\n",
    "            c += 1\n",
    "            flag_c = c < c_len\n",
    "\n",
    "        return dx\n",
    "\n",
    "    def backward(self, delta_y):\n",
    "        c_len, w_len, h_len = self.inputs.shape\n",
    "        if c_len < 0 or w_len < 0 or h_len < 0:\n",
    "            sys.exit(\"Inputs should not be negative\")\n",
    "        result = self.backward_out(c_len, w_len, h_len, delta_y)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(inputs, labels):\n",
    "    return -np.log(np.sum(labels.reshape(1,labels.shape[0])*inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten:\n",
    "    def forward(self, i):\n",
    "        self.c_len = i.shape[0]\n",
    "        self.w_len = i.shape[1]\n",
    "        self.h_len = i.shape[2]\n",
    "        return i.reshape(1, i.shape[0]*i.shape[1]*i.shape[2])\n",
    "    def backward(self, y):\n",
    "        return y.reshape(self.c_len, self.w_len, self.h_len)\n",
    "    def extract(self): \n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullyConnectedLayer:\n",
    "\n",
    "    def __init__(self, num_inputs, num_outputs, learning_rate):\n",
    "        if num_inputs < 0 or num_outputs < 0:\n",
    "            print(\"invalid values for num_inputs and num_outputs\")\n",
    "            return\n",
    "        self.weights = 0.01*np.random.rand(num_inputs, num_outputs)\n",
    "        self.bias = np.zeros((num_outputs, 1))\n",
    "        if learning_rate == 0:\n",
    "            print(\"invalid values for learning_rate\")\n",
    "            return\n",
    "        self.lr = learning_rate\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        self.inputs = inputs\n",
    "        return np.dot(self.inputs, self.weights) + self.bias.T\n",
    "\n",
    "    def backward(self, dy):\n",
    "        if dy.shape[0] == self.inputs.shape[0]:\n",
    "            dy = dy.T\n",
    "        dw = dy.dot(self.inputs)\n",
    "        db = np.sum(dy, axis=1, keepdims=True)\n",
    "        dx = np.dot(dy.T, self.weights.T)\n",
    "\n",
    "        self.weights -= self.lr * dw.T\n",
    "        self.bias -= self.lr * db\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax:\n",
    "    def forward(self, inputs):\n",
    "        tmp = np.exp(inputs, dtype=np.float)\n",
    "        self.out = tmp/np.sum(tmp)\n",
    "        return self.out\n",
    "    def backward(self, dy):\n",
    "        return self.out.T - dy.reshape(dy.shape[0],1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN:\n",
    "    def __init__(self, _layers):\n",
    "        self.layers = _layers\n",
    "        self.lay_num = len(layers)\n",
    "        \n",
    "    def get_data(self, trn_X, trn_y, i, batch):\n",
    "        flag = True\n",
    "        len_0 = trn_X.shape[0] \n",
    "        if batch > 0:\n",
    "            self.b = batch\n",
    "            flag = (len_0 - batch - i > 0)\n",
    "        else:\n",
    "            sys.exit(\"batch cannot be negative\")  \n",
    "        i2 = len_0\n",
    "        if flag:\n",
    "            i2 = i + batch\n",
    "        return trn_X[i:i2], trn_y[i:i2]\n",
    "\n",
    "    def forward(self, input_x):\n",
    "        for l in range(self.lay_num):\n",
    "            output = self.layers[l].forward(input_x)\n",
    "            input_x = output\n",
    "        return output\n",
    "\n",
    "    def backward(self, output_y):\n",
    "        l = lay_num\n",
    "        flag = (l >= 0)\n",
    "        out = output_y\n",
    "        while flag:\n",
    "            out = self.layers[l].backward(out)\n",
    "            l -= 1\n",
    "            flag = (l >= 0)\n",
    "\n",
    "    def train(self, training_data, training_label, batch_size, epoch):\n",
    "        acc_sum = 0\n",
    "        X0_len = training_data.shape[0]\n",
    "        for e in range(epoch):\n",
    "            batch_index = 0\n",
    "            flag = (batch_index < X0_len)\n",
    "            while flag:\n",
    "                # get the data\n",
    "                data, label = self.get_data(training_data, training_label, i, batch_size) \n",
    "                loss = 0\n",
    "                acc = 0\n",
    "\n",
    "                for b in range(len(data)):\n",
    "                    x = data[b]\n",
    "                    y = label[b]\n",
    "\n",
    "                    # forward\n",
    "                    output = self.forward(x)\n",
    "\n",
    "                    loss += cross_entropy(output, y)\n",
    "\n",
    "                    predict_y = np.argmax(output)\n",
    "                    real_y = np.argmax(y)\n",
    "                    flag = (predict_y != real_y)\n",
    "\n",
    "                    if flag:\n",
    "                        acc += 0\n",
    "                        acc_sum += 0\n",
    "                    else:\n",
    "                        acc += 1\n",
    "                        acc_sum += 1\n",
    "                    #backward\n",
    "                    self.backward(y)\n",
    "                batch_index += batch_size\n",
    "                flag = (batch_index < X0_len)\n",
    "\n",
    "\n",
    "                # result\n",
    "                loss /= batch_size\n",
    "                batch_acc = float(acc) / float(batch_size)\n",
    "                training_acc = float(acc_sum) / float((batch_index + batch_size) * (e + 1))\n",
    " \n",
    "    def predict(self, x):\n",
    "        return self.forward(x)\n",
    "\n",
    "    def test(self, data, label, test_size):\n",
    "        total_acc = 0\n",
    "        for i in range(test_size):\n",
    "            x = data[i]\n",
    "            y = label[i]\n",
    "\n",
    "            predict_y = np.argmax(self.predict(x))\n",
    "            real_y = np.argmax(y)\n",
    "            if predict_y != real_y:\n",
    "                total_acc += 0\n",
    "            else:\n",
    "                total_acc += 1\n",
    "\n",
    "        return  float(total_acc) / float(test_size)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Nov 17 15:03:57 2020\n",
    "\n",
    "@author: MoHan\n",
    "\"\"\"\n",
    "\n",
    "# libraries needed\n",
    "import os\n",
    "\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy \n",
    "\n",
    "# note: if tensorflow is not install, run \"pip install --upgrade tensorflow\"\n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "test_dir = \"./dataset/test_set\"\n",
    "train_dir = \"./dataset/training_set\"\n",
    "\n",
    "train_dir_cats = train_dir + \"/cats\"\n",
    "train_dir_dogs = train_dir + \"/dogs\"\n",
    "test_dir_cats = test_dir + \"/cats\"\n",
    "test_dir_dogs = test_dir + \"/dogs\"\n",
    "\n",
    "train_data = []\n",
    "train_data_label = []\n",
    "test_data = []\n",
    "test_data_label = []\n",
    "\n",
    "# Only transformed to gray pic\n",
    "def normal_transform (imgpath):\n",
    "    img = cv2.imread(imgpath)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    img = cv2.resize(img, (28,28))\n",
    "    return Image.fromarray(img)\n",
    "\n",
    "# Preprocessed using gaussian_canny\n",
    "def gaussian_canny_transform (imgpath):\n",
    "    img = cv2.imread(imgpath)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    gaussian = cv2.GaussianBlur(img, (3,3), 0)\n",
    "    gaussian = gaussian.astype(numpy.uint8)\n",
    "    canny = cv2.Canny(gaussian, 50, 50)\n",
    "    canny = cv2.resize(canny, (28,28))\n",
    "    return Image.fromarray(canny)\n",
    "\n",
    "# Reading training data\n",
    "def read_training_data(train_data, train_data_label, dir, label):\n",
    "    for filename in os.listdir(dir):\n",
    "        imgpath = dir + \"/\" + filename\n",
    "        img = normal_transform(imgpath)\n",
    "        train_data.append([numpy.asarray(img)])\n",
    "        train_data_label.append((label))\n",
    "\n",
    "# Reading testing data\n",
    "def read_testing_data(test_data, test_data_label, dir, label):\n",
    "    for filename in os.listdir(dir):\n",
    "        imgpath = dir + \"/\" + filename\n",
    "        img = normal_transform(imgpath)\n",
    "        test_data.append([numpy.asarray(img)])\n",
    "        test_data_label.append((label))\n",
    "\n",
    "#read gray images into train_data and train_data_label\n",
    "read_training_data(train_data, train_data_label, train_dir_cats, [0,1])\n",
    "#train_data =train_data[0:250]\n",
    "#train_data_label =train_data_label[0:250]\n",
    "read_training_data(train_data, train_data_label, train_dir_dogs, [1,0])\n",
    "#train_data =train_data[0:500]\n",
    "#train_data_label =train_data_label[0:500]\n",
    "for i in range(0,len(train_data)//2,2):\n",
    "               tmp=train_data[i]\n",
    "               train_data[i] =train_data[len(train_data)-1-i]\n",
    "               train_data[len(train_data)-1-i] =tmp\n",
    "               #print(train_data_label[i])\n",
    "               tlabel = train_data_label[i]\n",
    "               train_data_label[i] = train_data_label[len(train_data)-1-i]\n",
    "               train_data_label[len(train_data)-1-i] =  tlabel\n",
    "               #print(train_data_label[i])\n",
    "               \n",
    "\n",
    "\n",
    "\n",
    "read_testing_data(test_data, test_data_label, test_dir_cats, [0,1])\n",
    "\n",
    "read_testing_data(test_data, test_data_label, test_dir_dogs, [1,0])\n",
    "for i in range(0,len(test_data)//2,3):\n",
    "               tmp = test_data[i]\n",
    "               test_data[i] =test_data[len(test_data)-1-i]\n",
    "               test_data[len(test_data)-1-i] =tmp\n",
    "               tlabel = test_data_label[i]\n",
    "               test_data_label[i] = test_data_label[len(test_data)-1-i]\n",
    "               test_data_label[len(test_data)-1-i] =  tlabel\n",
    "               i=i+1\n",
    "train_data = train_data[0:500]\n",
    "train_data_label=train_data_label[0:500]\n",
    "test_data=test_data[1000:1200]\n",
    "test_data_label =test_data_label[1000:1200]\n",
    "\n",
    "train_data = numpy.array(train_data)\n",
    "\n",
    "test_data = numpy.array(test_data)\n",
    "\n",
    "train_data_label = numpy.array(train_data_label)\n",
    "\n",
    "test_data_label = numpy.array(test_data_label)\n",
    "\n",
    "lr = 0.01\n",
    "c1 = ConvolutionLayer(1, 6, 5, 5, 2, 1, learning_rate=lr)\n",
    "r1 = ReLu()\n",
    "\n",
    "m1 = MaxPoolingLayer(2, 2, 2)\n",
    "c2 = ConvolutionLayer(6, 16, 5, 5, 0, 1, learning_rate=lr)\n",
    "r2 = ReLu()\n",
    "m2 = MaxPoolingLayer(2, 2, 2)\n",
    "c3 = ConvolutionLayer(16, 120, 5, 5, 0, 1, learning_rate=lr)\n",
    "r3 = ReLu()\n",
    "f1 = Flatten()\n",
    "fc1 = FullyConnectedLayer(120, 60, learning_rate=lr)\n",
    "r4 = ReLu()\n",
    "fc2 = FullyConnectedLayer(60, 2, learning_rate=lr)\n",
    "s1 = Softmax()\n",
    "\n",
    "layers = [c1, r1, m1, c2, r2, m2, c3, r3, f1, fc1, r4, fc2, s1]\n",
    "\n",
    "cnn = CNN(layers)\n",
    "\n",
    "#print('Training Lenet......')\n",
    "cnn.train(training_data=train_data,training_label=train_data_label,batch_size=20,epoch=1)\n",
    "\n",
    "#print('Testing Lenet......')\n",
    "accuracy = cnn.test(data=test_data,label=test_data_label,test_size=200)\n",
    "print('Testing accuracy:'+str(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write result into txt\n",
    "f = open(\"CNN_result.txt\", \"w\")\n",
    "f.write('Testing accuracy:'+str(accuracy*100)+'%')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "1baa965d5efe3ac65b79dfc60c0d706280b1da80fedb7760faf2759126c4f253"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}