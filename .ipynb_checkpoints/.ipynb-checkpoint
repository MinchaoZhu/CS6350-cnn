{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "\n",
    "import math\n",
    "from network import Net\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy \n",
    "\n",
    "# note: if tensorflow is not install, run \"pip install --upgrade tensorflow\"\n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "test_dir = \"./dataset/test_set\"\n",
    "train_dir = \"./dataset/training_set\"\n",
    "\n",
    "train_dir_cats = train_dir + \"/cats\"\n",
    "train_dir_dogs = train_dir + \"/dogs\"\n",
    "test_dir_cats = test_dir + \"/cats\"\n",
    "test_dir_dogs = test_dir + \"/dogs\"\n",
    "\n",
    "train_data = []\n",
    "train_data_label = []\n",
    "test_data = []\n",
    "test_data_label = []\n",
    "\n",
    "# Only transformed to gray pic\n",
    "def normal_transform (imgpath):\n",
    "    img = cv2.imread(imgpath)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    img = cv2.resize(img, (28,28))\n",
    "    return Image.fromarray(img)\n",
    "\n",
    "# Preprocessed using gaussian_canny\n",
    "def gaussian_canny_transform (imgpath):\n",
    "    img = cv2.imread(imgpath)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    gaussian = cv2.GaussianBlur(img, (3,3), 0)\n",
    "    gaussian = gaussian.astype(numpy.uint8)\n",
    "    canny = cv2.Canny(gaussian, 50, 50)\n",
    "    canny = cv2.resize(canny, (28,28))\n",
    "    return Image.fromarray(canny)\n",
    "\n",
    "# Preprocessed using sobel\n",
    "def sobel_transform (imgpath):\n",
    "    img = cv2.imread(imgpath)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    height, weight = img.shape\n",
    "    sobel = numpy.zeros((height, weight, 1), numpy.uint8)\n",
    "    for i in range(0,height-2):\n",
    "        for j in range(0,weight-2):\n",
    "            gy=img[i,j]*1+img[i,j+1]*2+img[i,j+2]*1-img[i+2,j]-2*img[i+2,j+1]-img[i+2,j+2]*1\n",
    "            gx=img[i,j]*1-img[i,j+2]+img[i+1,j]*2-2*img[i+1,j+2]+img[i+2,j]-img[i+2,j+2]\n",
    "            grad=math.sqrt(gx*gx+gy*gy)\n",
    "            if grad>50:\n",
    "                sobel[i,j]=255\n",
    "            else:\n",
    "                sobel[i,j]=0\n",
    "    print(sobel)\n",
    "    # return Image.fromarray(numpy.uint8(sobel))\n",
    "\n",
    "# Reading training data\n",
    "def read_training_data(train_data, train_data_label, dir, label):\n",
    "    for filename in os.listdir(dir):\n",
    "        imgpath = dir + \"/\" + filename\n",
    "        img = normal_transform(imgpath)\n",
    "        train_data.append([numpy.asarray(img)])\n",
    "        train_data_label.append((label))\n",
    "\n",
    "# Reading testing data\n",
    "def read_testing_data(test_data, test_data_label, dir, label):\n",
    "    for filename in os.listdir(dir):\n",
    "        imgpath = dir + \"/\" + filename\n",
    "        img = normal_transform(imgpath)\n",
    "        test_data.append([numpy.asarray(img)])\n",
    "        test_data_label.append((label))\n",
    "\n",
    "#read gray images into train_data and train_data_label\n",
    "read_training_data(train_data, train_data_label, train_dir_cats, (0,1))\n",
    "#train_data =train_data[0:250]\n",
    "#train_data_label =train_data_label[0:250]\n",
    "read_training_data(train_data, train_data_label, train_dir_dogs, (1,0))\n",
    "#train_data =train_data[0:500]\n",
    "#train_data_label =train_data_label[0:500]\n",
    "for i in range(len(train_data)//2):\n",
    "               tmp = train_data[i]\n",
    "               train_data[i] =train_data[len(train_data)-1-i]\n",
    "               train_data[len(train_data)-1-i] =tmp\n",
    "               tlabel = train_data_label[i]\n",
    "               train_data_label[i] = train_data_label[len(train_data)-1-i]\n",
    "               train_data_label[len(train_data)-1-i] =  tlabel\n",
    "\n",
    "\n",
    "#read gray images into test_data and test_data_label\n",
    "read_testing_data(test_data, test_data_label, test_dir_cats, (0,1))\n",
    "#test_data =test_data[0:100]\n",
    "#test_data_label =test_data_label[0:100]\n",
    "read_testing_data(test_data, test_data_label, test_dir_dogs, (1,0))\n",
    "for i in range(len(test_data)//2):\n",
    "               tmp = test_data[i]\n",
    "               test_data[i] =test_data[len(test_data)-1-i]\n",
    "               test_data[len(test_data)-1-i] =tmp\n",
    "               tlabel = test_data_label[i]\n",
    "               test_data_label[i] = test_data_label[len(test_data)-1-i]\n",
    "               test_data_label[len(test_data)-1-i] =  tlabel\n",
    "#test_data =test_data[0:200]\n",
    "#test_data_label =test_data_label[0:200]\n",
    "train_data =train_data[0:500]\n",
    "train_data_label =train_data_label[0:500]\n",
    "test_data =test_data[1000:1200]\n",
    "test_data_label =test_data_label[1000:1200]\n",
    "train_data = numpy.array(train_data)\n",
    "\n",
    "test_data = numpy.array(test_data)\n",
    "\n",
    "train_data_label = numpy.array(train_data_label)\n",
    "\n",
    "test_data_label = numpy.array(test_data_label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data.shape, train_data_label.shape)\n",
    "print(test_data.shape, test_data_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLayer:\n",
    "  # 卷积层，输入包含四个参数，这里默认使用valid padding，即不对输入做padding\n",
    "    def __init__(self, num_filters, length, width, stride):\n",
    "        \"\"\"\n",
    "        num_filters: 卷积核个数\n",
    "        length：     卷积核长\n",
    "        width：      卷积核宽\n",
    "        stride：     卷积核步长\n",
    "        \"\"\"\n",
    "        self.num_filters = num_filters\n",
    "        self.length = length\n",
    "        self.width = width\n",
    "        self.stride = stride\n",
    "        # 所有卷积参数构成一个3维矩阵， (num_filters, lenght, width)\n",
    "        # 参数随机初始化，除length*width减小方差\n",
    "        self.filters = np.random.randn(num_filters, length, width) / (length*width)\n",
    "        \n",
    "    def iterate_regions(self, image):\n",
    "        \"\"\"\n",
    "        输入： image，单通道图片矩阵\n",
    "        输出： (im_region, i, j), 所有length x width 大小的图片区域及对应位置索引\n",
    "        \"\"\"\n",
    "        h, w = image.shape\n",
    "        h_new = (h-self.length) // self.stride + 1\n",
    "        w_new = (w-self.width) // self.stride + 1\n",
    "        for i in range(h_new):\n",
    "            for j in range(w_new):\n",
    "                im_region = image[i*self.stride:(i*self.stride + self.length), j*self.stride:(j*self.stride + self.width)]\n",
    "                yield im_region, i, j\n",
    "                \n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        输入： input， 二维矩阵\n",
    "        输出：(h_new, w_new, num_filters)， 三维卷积输出\n",
    "        \"\"\"\n",
    "        h, w = input.shape\n",
    "        h_new = (h-self.length) // self.stride + 1\n",
    "        w_new = (w-self.width) // self.stride + 1\n",
    "        output = np.zeros((h_new, w_new, self.num_filters))\n",
    "        for im_region, i, j in self.iterate_regions(input):\n",
    "            output[i, j] = np.sum(im_region * self.filters, axis=(1, 2))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPoolingLayer:\n",
    "  # 池化层\n",
    "    def __init__(self, num_filters, length, width, stride):\n",
    "        \"\"\"\n",
    "        num_filters: 池化核个数\n",
    "        length：     池化核长\n",
    "        width：      池化核宽\n",
    "        stride：     池化核步长\n",
    "        \"\"\"\n",
    "        self.num_filters = num_filters\n",
    "        self.length = length\n",
    "        self.width = width\n",
    "        self.stride = stride\n",
    "        \n",
    "    def iterate_regions(self, image):\n",
    "        \"\"\"\n",
    "        输入： image，二维矩阵\n",
    "        输出： (im_region, i, j), 所有length x width 大小的矩阵区域及对应位置索引\n",
    "        \"\"\"\n",
    "        h, w, _ = image.shape\n",
    "        h_new = (h-self.length) // self.stride + 1\n",
    "        w_new = (w-self.width) // self.stride + 1\n",
    "        for i in range(h_new):\n",
    "            for j in range(w_new):\n",
    "                im_region = image[(i * self.stride):(i * self.stride + self.length), (j * self.stride):(j * self.stride + self.width)]\n",
    "                yield im_region, i, j\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        input: (h, w, num_filters),3维矩阵\n",
    "        output: (h / 2, w / 2, num_filters).\n",
    "        \"\"\"\n",
    "        h, w, num_filters = input.shape\n",
    "        h_new = (h-self.length) // self.stride + 1\n",
    "        w_new = (w-self.width) // self.stride + 1\n",
    "        output = np.zeros((h_new, w_new, num_filters))\n",
    "        for im_region, i, j in self.iterate_regions(input):\n",
    "            output[i, j] = np.amax(im_region, axis=(0, 1))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxLayer:\n",
    "  # 全连接层带softmax激活函数.\n",
    "    def __init__(self, input_len, nodes):\n",
    "        # 参随机数初始化\n",
    "        self.weights = np.random.randn(input_len, nodes) / input_len\n",
    "        self.biases = np.zeros(nodes)\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        input：input can be any array with any dimensions \n",
    "        output：一维数组，表示各类别概率\n",
    "        \"\"\"\n",
    "        input = input.flatten()\n",
    "\n",
    "        input_len, nodes = self.weights.shape\n",
    "\n",
    "        totals = np.dot(input, self.weights) + self.biases\n",
    "        exp = np.exp(totals)\n",
    "        return exp / np.sum(exp, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxLayer:\n",
    "  # 全连接层带softmax激活函数.\n",
    "\n",
    "    def __init__(self, input_len, nodes):\n",
    "        # 参随机数初始化\n",
    "        self.weights = np.random.randn(input_len, nodes) / input_len\n",
    "        self.biases = np.zeros(nodes)\n",
    "        \n",
    "    def backprop(self, d_L_d_out, learning_rate):\n",
    "        \"\"\"\n",
    "        input: (d_L_d_out,learning_rate), (损失对输出结果的导数,学习率)\n",
    "        output: d_L_d_inputs， 损失对输入数据的导数\n",
    "        \"\"\"\n",
    "        # d_L_d_out当中只有真实标签所在位置数值不为0\n",
    "        for i, gradient in enumerate(d_L_d_out):\n",
    "            if gradient == 0:\n",
    "                continue\n",
    "\n",
    "            # e^totals\n",
    "            t_exp = np.exp(self.last_totals)\n",
    "\n",
    "            # Sum of all e^totals\n",
    "            S = np.sum(t_exp)\n",
    "\n",
    "            # out[i] 对输出求导\n",
    "            d_out_d_t = -t_exp[i] * t_exp / (S ** 2)\n",
    "            d_out_d_t[i] = t_exp[i] * (S - t_exp[i]) / (S ** 2)\n",
    "\n",
    "            # 输出对 weights/biases/input 的梯度\n",
    "            d_t_d_w = self.last_input\n",
    "            d_t_d_b = 1\n",
    "            d_t_d_inputs = self.weights\n",
    "\n",
    "            # 损失对输出的梯度\n",
    "            d_L_d_t = gradient * d_out_d_t\n",
    "\n",
    "            # 链式法则求损失对weights/biases/input 的梯度\n",
    "            d_L_d_w = d_t_d_w[np.newaxis].T @ d_L_d_t[np.newaxis]\n",
    "            d_L_d_b = d_L_d_t * d_t_d_b\n",
    "            d_L_d_inputs = d_t_d_inputs @ d_L_d_t\n",
    "\n",
    "            # 更新 weights / biases\n",
    "            self.weights -= learning_rate * d_L_d_w\n",
    "            self.biases -= learning_rate * d_L_d_b\n",
    "        return d_L_d_inputs.reshape(self.last_input_shape)\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        input：input can be any array with any dimensions \n",
    "        output：一维数组，表示各类别概率\n",
    "        \"\"\"\n",
    "        self.last_input_shape = input.shape\n",
    "        \n",
    "        input = input.flatten()\n",
    "        self.last_input = input\n",
    "        \n",
    "        input_len, nodes = self.weights.shape\n",
    "\n",
    "        totals = np.dot(input, self.weights) + self.biases\n",
    "        \n",
    "        self.last_totals = totals\n",
    "        \n",
    "        exp = np.exp(totals)\n",
    "        return exp / np.sum(exp, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPoolLayer:\n",
    "  # A Max Pooling layer .\n",
    "    def __init__(self, num_filters, length, width, stride):\n",
    "        self.num_filters = num_filters\n",
    "        self.length = length\n",
    "        self.width = width\n",
    "        self.stride = stride\n",
    "        \n",
    "    def iterate_regions(self, image):\n",
    "        \"\"\"\n",
    "        输入： image，二维矩阵\n",
    "        输出： (im_region, i, j), 所有length x width 大小的矩阵区域及对应位置索引\n",
    "        \"\"\"\n",
    "        h, w, _ = image.shape\n",
    "        h_new = (h-self.length) // self.stride + 1\n",
    "        w_new = (w-self.width) // self.stride + 1\n",
    "        for i in range(h_new):\n",
    "            for j in range(w_new):\n",
    "                im_region = image[(i * self.stride):(i * self.stride + self.length), (j * self.stride):(j * self.stride + self.width)]\n",
    "                yield im_region, i, j\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        输入： image，二维矩阵\n",
    "        输出： (im_region, i, j), 所有length x width 大小的矩阵区域及对应位置索引\n",
    "        \"\"\"\n",
    "        h, w, num_filters = input.shape\n",
    "        self.last_input = input\n",
    "        \n",
    "        h_new = (h-self.length) // self.stride + 1\n",
    "        w_new = (w-self.width) // self.stride + 1\n",
    "        output = np.zeros((h_new, w_new, num_filters))\n",
    "\n",
    "        for im_region, i, j in self.iterate_regions(input):\n",
    "            output[i, j] = np.amax(im_region, axis=(0, 1))\n",
    "        return output\n",
    "    def backprop(self, d_L_d_out):\n",
    "        \"\"\"\n",
    "        input: (h, w, num_filters),3维矩阵\n",
    "        output: (h / 2, w / 2, num_filters).\n",
    "        \"\"\"\n",
    "        d_L_d_input = np.zeros(self.last_input.shape)\n",
    "\n",
    "        for im_region, i, j in self.iterate_regions(self.last_input):\n",
    "            h, w, f = im_region.shape\n",
    "            amax = np.amax(im_region, axis=(0, 1))\n",
    "\n",
    "            for i2 in range(h):\n",
    "                for j2 in range(w):\n",
    "                    for f2 in range(f):\n",
    "                        # If this pixel was the max value, copy the gradient to it.\n",
    "                        if im_region[i2, j2, f2] == amax[f2]:\n",
    "                            d_L_d_input[i * self.length + i2, j * self.width + j2, f2] = d_L_d_out[i, j, f2]\n",
    "\n",
    "        return d_L_d_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class ConvLayer:\n",
    "  # A Convolution layer\n",
    "    def __init__(self, num_filters, length, width, stride):\n",
    "        \"\"\"\n",
    "        num_filters: 卷积核个数\n",
    "        length：     卷积核长\n",
    "        width：      卷积核宽\n",
    "        stride：     卷积核步长\n",
    "        \"\"\"\n",
    "        self.num_filters = num_filters\n",
    "        self.length = length\n",
    "        self.width = width\n",
    "        self.stride = stride\n",
    "\n",
    "        # 所有卷积参数构成一个3维矩阵， (num_filters, lenght, width)\n",
    "        # 参数随机初始化，除length*width减小方差\n",
    "        self.filters = np.random.randn(num_filters, length, width) / (length*width)\n",
    "    def iterate_regions(self, image):\n",
    "        \"\"\"\n",
    "        输入： image，二维矩阵\n",
    "        输出： (im_region, i, j), 所有length x width 大小的矩阵区域及对应位置索引\n",
    "        \"\"\"\n",
    "        h, w = image.shape\n",
    "        h_new = (h-self.length) // self.stride + 1\n",
    "        w_new = (w-self.width) // self.stride + 1\n",
    "        for i in range(h_new):\n",
    "            for j in range(w_new):\n",
    "                im_region = image[i*self.stride:(i*self.stride + self.length), j*self.stride:(j*self.stride + self.width)]\n",
    "                yield im_region, i, j\n",
    "    def backprop(self, d_L_d_out, learning_rate):\n",
    "        \"\"\"\n",
    "        input: (d_L_d_out,learning_rate), (损失对输出结果的导数,学习率)\n",
    "        output: d_L_d_inputs， 损失对输入数据的导数\n",
    "        \"\"\"\n",
    "        d_L_d_filters = np.zeros(self.filters.shape)\n",
    "\n",
    "        for im_region, i, j in self.iterate_regions(self.last_input):\n",
    "            for f in range(self.num_filters):\n",
    "                d_L_d_filters[f] += d_L_d_out[i, j, f] * im_region\n",
    "\n",
    "        # 更新卷积参数\n",
    "        self.filters -= learning_rate * d_L_d_filters\n",
    "\n",
    "        return None\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        输入： input， 二维矩阵\n",
    "        输出：(h_new, w_new, num_filters)， 三维卷积输出\n",
    "        \"\"\"\n",
    "        h, w = input.shape\n",
    "        self.last_input = input\n",
    "        h_new = (h-self.length) // self.stride + 1\n",
    "        w_new = (w-self.width) // self.stride + 1\n",
    "        output = np.zeros((h_new, w_new, self.num_filters))\n",
    "\n",
    "        for im_region, i, j in self.iterate_regions(input):\n",
    "            output[i, j] = np.sum(im_region * self.filters, axis=(1, 2))\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_X.reshape(-1,28,28)\n",
    "train_labels = train_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 28, 28)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 10)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 28, 28)\n",
      "(26, 26, 8)\n",
      "(13, 13, 8)\n",
      "[0.09969568 0.1002037  0.10043689 0.09985315 0.10023377 0.09903822\n",
      " 0.10010212 0.09976231 0.10026143 0.10041273]\n"
     ]
    }
   ],
   "source": [
    "train_images = train_X.reshape(-1,28,28)\n",
    "train_labels = train_Y\n",
    "print(train_images.shape)\n",
    "conv = ConvLayer(8,3,3,1)\n",
    "output = conv.forward(train_images[0])\n",
    "print(output.shape) # (26, 26, 8)\n",
    "pool = MaxPoolLayer(8,2,2,2)\n",
    "output = pool.forward(output)\n",
    "print(output.shape) # (13, 13, 8)\n",
    "softmax = SoftmaxLayer(13 * 13 * 8, 10) # 13x13x8 -> 10\n",
    "out = softmax.forward(output)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 6, 8)\n"
     ]
    }
   ],
   "source": [
    "pool = MaxPoolLayer(8,2,2,2)\n",
    "output = pool.forward(output)\n",
    "print(output.shape) # (13, 13, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26, 26, 8)\n"
     ]
    }
   ],
   "source": [
    "conv2 = ConvLayer(8,3,3,1)\n",
    "output = conv2.forward(train_images[0])\n",
    "print(output.shape) # (26, 26, 8)\n",
    "softmax = SoftmaxLayer(13 * 13 * 8, 10) # 13x13x8 -> 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = SoftmaxLayer(13 * 13 * 8, 10) # 13x13x8 -> 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (5408,) and (1352,10) not aligned: 5408 (dim 0) != 1352 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-0b862177e725>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-63-62f6ed1243e3>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0minput_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mtotals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbiases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_totals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (5408,) and (1352,10) not aligned: 5408 (dim 0) != 1352 (dim 0)"
     ]
    }
   ],
   "source": [
    "out = softmax.forward(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(out*train_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo使用一千张图片做训练与测试， 可以使用全部的训练和测试图片，训练时间会比较久一些\n",
    "train_images = train_X.reshape(-1,28,28)[:1000]\n",
    "train_labels = train_Y[:1000]\n",
    "\n",
    "test_images = test_X.reshape(-1,28,28)[:1000]\n",
    "test_labels = test_Y[:1000]\n",
    "\n",
    "print(train_images.shape, train_labels.shape)\n",
    "print(test_images.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = ConvLayer(8,3,3,1)                  # 28x28x1 -> 26x26x8\n",
    "pool = MaxPoolingLayer(8,2,2,2)                  # 26x26x8 -> 13x13x8\n",
    "softmax = SoftmaxLayer(13 * 13 * 8, 10) # 13x13x8 -> 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(image, label):\n",
    "    \"\"\"\n",
    "    CNN 前向传播并计算 accuracy 与 cross-entropy loss.\n",
    "    - image： 2d numpy array\n",
    "    - label： one-hot encoded digit\n",
    "    \"\"\"\n",
    "    \n",
    "    # 将图片像素值从 [0, 255] 转换到 [-0.5, 0.5] ，这样更便于网络进行训练\n",
    "    out = conv.forward((image / 255.0) - 0.5)\n",
    "    out = pool.forward(out)\n",
    "    out = softmax.forward(out)\n",
    "\n",
    "    # Calculate cross-entropy loss and accuracy. np.log() is the natural log.\n",
    "    digit = np.argmax(label)\n",
    "    loss = -np.log(out[digit])\n",
    "    acc = 1 if np.argmax(out) == digit else 0\n",
    "    return out, loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward(train_images[0], train_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(im, label, lr=0.01):\n",
    "    \"\"\"\n",
    "    前向传播->后向传播->更新梯度->计算损失及准确率\n",
    "    image: 2d numpy array\n",
    "    label: one-hot encoded digit\n",
    "    lr: learning rate\n",
    "    \"\"\"\n",
    "    # Forward\n",
    "    out, loss, acc = forward(im, label)\n",
    "\n",
    "    # Calculate initial gradient\n",
    "    digit = np.argmax(label)\n",
    "    gradient = np.zeros(10)\n",
    "    gradient[digit] = -1 / out[digit]\n",
    "\n",
    "    # Backprop\n",
    "    gradient = softmax.backprop(gradient, lr)\n",
    "    gradient = pool.backprop(gradient)\n",
    "    gradient = conv.backprop(gradient, lr)\n",
    "\n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(train_images[0], train_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the CNN for 3 epochs\n",
    "for epoch in range(3):\n",
    "    print('--- Epoch %d ---' % (epoch + 1))\n",
    "    # Shuffle the training data\n",
    "    permutation = np.random.permutation(len(train_images))\n",
    "    train_images = train_images[permutation]\n",
    "    train_labels = train_labels[permutation]\n",
    "    # Train!\n",
    "    loss = 0\n",
    "    num_correct = 0\n",
    "    for i, (image, label) in enumerate(zip(train_images, train_labels)):\n",
    "        if i > 0 and i % 100 == 99:\n",
    "            print('[Step %d] Past 100 steps: Average Loss %.3f | Accuracy: %d%%' %(i + 1, loss / 100, num_correct))\n",
    "            loss = 0\n",
    "            num_correct = 0\n",
    "        out = conv.forward((image / 255.0) - 0.5)\n",
    "        out = pool.forward(out)\n",
    "        out = softmax.forward(out)\n",
    "        # Calculate cross-entropy loss and accuracy. np.log() is the natural log.\n",
    "        digit = np.argmax(label)\n",
    "        loss = -np.log(out[digit])\n",
    "        acc = 1 if np.argmax(out) == digit else 0\n",
    "            # Calculate initial gradient\n",
    "        gradient = np.zeros(10)\n",
    "        gradient[digit] = -1 / out[digit]\n",
    "        # Backprop\n",
    "        lr = 0.01\n",
    "        gradient = softmax.backprop(gradient, lr)\n",
    "        gradient = pool.backprop(gradient)\n",
    "        gradient = conv.backprop(gradient, lr)\n",
    "        loss += l\n",
    "        num_correct += acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo使用一千张图片做训练与测试， 可以使用全部的训练和测试图片，训练时间会比较久一些\n",
    "train_images = train_X.reshape(-1,28,28)[:1000]\n",
    "train_labels = train_Y[:1000]\n",
    "\n",
    "test_images = test_X.reshape(-1,28,28)[:1000]\n",
    "test_labels = test_Y[:1000]\n",
    "\n",
    "print(train_images.shape, train_labels.shape)\n",
    "print(test_images.shape, test_labels.shape)\n",
    "\n",
    "conv = ConvLayer(8,3,3,1)                  # 28x28x1 -> 26x26x8\n",
    "pool = MaxPoolingLayer(8,2,2,2)                  # 26x26x8 -> 13x13x8\n",
    "softmax = SoftmaxLayer(13 * 13 * 8, 10) # 13x13x8 -> 10\n",
    "\n",
    "def forward(image, label):\n",
    "    \"\"\"\n",
    "    CNN 前向传播并计算 accuracy 与 cross-entropy loss.\n",
    "    - image： 2d numpy array\n",
    "    - label： one-hot encoded digit\n",
    "    \"\"\"\n",
    "    \n",
    "    # 将图片像素值从 [0, 255] 转换到 [-0.5, 0.5] ，这样更便于网络进行训练\n",
    "    out = conv.forward((image / 255) - 0.5)\n",
    "    out = pool.forward(out)\n",
    "    out = softmax.forward(out)\n",
    "\n",
    "    # Calculate cross-entropy loss and accuracy. np.log() is the natural log.\n",
    "    digit = np.argmax(label)\n",
    "    loss = -np.log(out[digit])\n",
    "    acc = 1 if np.argmax(out) == digit else 0\n",
    "    return out, loss, acc\n",
    "\n",
    "def train(im, label, lr=0.005):\n",
    "    \"\"\"\n",
    "    前向传播->后向传播->更新梯度->计算损失及准确率\n",
    "    image: 2d numpy array\n",
    "    label: one-hot encoded digit\n",
    "    lr: learning rate\n",
    "    \"\"\"\n",
    "    # Forward\n",
    "    out, loss, acc = forward(im, label)\n",
    "\n",
    "    # Calculate initial gradient\n",
    "    digit = np.argmax(label)\n",
    "    gradient = np.zeros(10)\n",
    "    gradient[digit] = -1 / out[digit]\n",
    "\n",
    "    # Backprop\n",
    "    gradient = softmax.backprop(gradient, lr)\n",
    "    gradient = pool.backprop(gradient)\n",
    "    gradient = conv.backprop(gradient, lr)\n",
    "\n",
    "    return loss, acc\n",
    "\n",
    "print('MNIST CNN initialized!')\n",
    "\n",
    "# Train the CNN for 3 epochs\n",
    "for epoch in range(3):\n",
    "    print('--- Epoch %d ---' % (epoch + 1))\n",
    "\n",
    "    # Shuffle the training data\n",
    "    permutation = np.random.permutation(len(train_images))\n",
    "    train_images = train_images[permutation]\n",
    "    train_labels = train_labels[permutation]\n",
    "\n",
    "    # Train!\n",
    "    loss = 0\n",
    "    num_correct = 0\n",
    "    for i, (im, label) in enumerate(zip(train_images, train_labels)):\n",
    "        if i > 0 and i % 100 == 99:\n",
    "            print('[Step %d] Past 100 steps: Average Loss %.3f | Accuracy: %d%%' %(i + 1, loss / 100, num_correct))\n",
    "            loss = 0\n",
    "            num_correct = 0\n",
    "\n",
    "        l, acc = train(im, label)\n",
    "        loss += l\n",
    "        num_correct += acc\n",
    "\n",
    "# Test the CNN\n",
    "print('\\n--- Testing the CNN ---')\n",
    "loss = 0\n",
    "num_correct = 0\n",
    "for im, label in zip(test_images, test_labels):\n",
    "    _, l, acc = forward(im, label)\n",
    "    loss += l\n",
    "    num_correct += acc\n",
    "\n",
    "num_tests = len(test_images)\n",
    "print('Test Loss:', loss / num_tests)\n",
    "print('Test Accuracy:', num_correct / num_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "train_images = mnist.train_images()\n",
    "train_labels = mnist.train_labels()\n",
    "test_images = mnist.test_images()\n",
    "test_labels = mnist.test_labels()\n",
    "\n",
    "train_images = (train_images / 255) - 0.5\n",
    "test_images = (test_images / 255) - 0.5\n",
    "\n",
    "train_images = np.expand_dims(train_images, axis=3)\n",
    "test_images = np.expand_dims(test_images, axis=3)\n",
    "\n",
    "model = Sequential([\n",
    "  Conv2D(8, 3, input_shape=(28, 28, 1), use_bias=False),\n",
    "  MaxPooling2D(pool_size=2),\n",
    "  Flatten(),\n",
    "  Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "model.compile(SGD(lr=.005), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(\n",
    "  train_images,\n",
    "  to_categorical(train_labels),\n",
    "  batch_size=1,\n",
    "  epochs=3,\n",
    "  validation_data=(test_images, to_categorical(test_labels)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
